{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import json\n",
    "import os \n",
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchtext.data import (Dataset, Field, LabelField, \n",
    "                            BucketIterator, Iterator, Example) \n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    # Data Path and Information\n",
    "    surnames_csv=\"data/surnames/surnames_with_splits.csv\",\n",
    "    model_state_file=\"model.pth\",\n",
    "    save_dir=\"model_storage\",\n",
    "    # Model hyper parameters\n",
    "    hidden_dim=300,\n",
    "    # Training  hyper parameters\n",
    "    seed=1337,\n",
    "    num_epochs=100,\n",
    "    early_stopping_criteria=5,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    # Runtime options\n",
    "    catch_keyboard_interrupt=True,\n",
    "    expand_filepaths_to_save_dir=True,\n",
    "    reload_from_files=False,\n",
    "    cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded filepaths: \n",
      "\tmodel_storage/model.pth\n",
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def handle_dirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "if args.expand_filepaths_to_save_dir:\n",
    "    args.model_state_file = os.path.join(args.save_dir,\n",
    "                                         args.model_state_file)\n",
    "    \n",
    "    print(\"Expanded filepaths: \")\n",
    "    print(\"\\t{}\".format(args.model_state_file))\n",
    "    \n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "set_seed_everywhere(args.seed, args.cuda)\n",
    "\n",
    "# handle dirs\n",
    "handle_dirs(args.save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames = pd.read_csv(args.surnames_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surname</th>\n",
       "      <th>nationality</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Piccoli</td>\n",
       "      <td>Italian</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matano</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batten</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yarnold</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tutton</td>\n",
       "      <td>English</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surname nationality  split\n",
       "0  Piccoli     Italian  train\n",
       "1   Matano    Japanese  train\n",
       "2   Batten     English  train\n",
       "3  Yarnold     English  train\n",
       "4   Tutton     English  train"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surnames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchText Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    text = [char for char in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURNAME = Field(sequential=True, pad_token=None, tokenize=tokenizer, lower=False)\n",
    "NATIONALITY = LabelField(dtype=torch.float32, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchText Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnamesDataset(Dataset):\n",
    "    def __init__(self, surnames_df, fields):\n",
    "        examples = []\n",
    "        for idx, row in tqdm_notebook(surnames_df.iterrows(), \n",
    "                                      total=surnames_df.shape[0]):\n",
    "            surname = row.surname\n",
    "            nationality = row.nationality\n",
    "            examples.append(Example.fromlist([surname, nationality], fields))\n",
    "        super().__init__(examples, fields)\n",
    "            \n",
    "    @staticmethod\n",
    "    def sort_key(data):\n",
    "        return len(data.surname)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, fields, surnames_df):\n",
    "        train_data = cls(surnames_df[surnames_df.split == \"train\"], fields)\n",
    "        val_data = cls(surnames_df[surnames_df.split == \"val\"], fields)\n",
    "        test_data = cls(surnames_df[surnames_df.split == \"test\"], fields)\n",
    "        return train_data, val_data, test_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bbe7c09a0f45068594d2f66cb13ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7685.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd84403fa7b40f68e85ade9cdfc18be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1647.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ede7443e8f1409baa30ce2aaeca576e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1648.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fields = [('surname', SURNAME), ('nationality', NATIONALITY)]\n",
    "train_data, val_data, test_data = SurnamesDataset.splits(fields, surnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'surname': ['P', 'i', 'c', 'c', 'o', 'l', 'i'], 'nationality': 'italian'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURNAME.build_vocab(train_data, min_freq=0, specials=['<unk>'])\n",
    "NATIONALITY.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['freqs', 'itos', 'unk_index', 'stoi', 'vectors'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(SURNAME.vocab).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SURNAME.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'freqs': Counter({'italian': 420,\n",
       "          'japanese': 542,\n",
       "          'english': 2080,\n",
       "          'russian': 1661,\n",
       "          'arabic': 1122,\n",
       "          'dutch': 165,\n",
       "          'french': 160,\n",
       "          'german': 403,\n",
       "          'polish': 84,\n",
       "          'irish': 128,\n",
       "          'czech': 290,\n",
       "          'greek': 109,\n",
       "          'spanish': 181,\n",
       "          'scottish': 52,\n",
       "          'portuguese': 39,\n",
       "          'chinese': 154,\n",
       "          'vietnamese': 41,\n",
       "          'korean': 54}),\n",
       " 'itos': ['english',\n",
       "  'russian',\n",
       "  'arabic',\n",
       "  'japanese',\n",
       "  'italian',\n",
       "  'german',\n",
       "  'czech',\n",
       "  'spanish',\n",
       "  'dutch',\n",
       "  'french',\n",
       "  'chinese',\n",
       "  'irish',\n",
       "  'greek',\n",
       "  'polish',\n",
       "  'korean',\n",
       "  'scottish',\n",
       "  'vietnamese',\n",
       "  'portuguese'],\n",
       " 'unk_index': None,\n",
       " 'stoi': defaultdict(None,\n",
       "             {'english': 0,\n",
       "              'russian': 1,\n",
       "              'arabic': 2,\n",
       "              'japanese': 3,\n",
       "              'italian': 4,\n",
       "              'german': 5,\n",
       "              'czech': 6,\n",
       "              'spanish': 7,\n",
       "              'dutch': 8,\n",
       "              'french': 9,\n",
       "              'chinese': 10,\n",
       "              'irish': 11,\n",
       "              'greek': 12,\n",
       "              'polish': 13,\n",
       "              'korean': 14,\n",
       "              'scottish': 15,\n",
       "              'vietnamese': 16,\n",
       "              'portuguese': 17}),\n",
       " 'vectors': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(NATIONALITY.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(object):\n",
    "    def __init__(self, surname_field):\n",
    "        self._surname_field = surname_field\n",
    "    \n",
    "    def vectorize(self, batch_matrix):\n",
    "        batch_size = batch_matrix.shape[1]\n",
    "        one_hot = torch.zeros((batch_size, len(self._surname_field.vocab.itos)), dtype=torch.long)\n",
    "        indices = batch_matrix.T\n",
    "        source = (indices!=0).long()\n",
    "        one_hot.scatter_(1, indices, source)\n",
    "        return one_hot[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh_vectorizer = Vectorizer(SURNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, val_iterator = BucketIterator.splits(\n",
    "    (train_data, val_data), \n",
    "    batch_size = args.batch_size,\n",
    "    sort_within_batch = False,\n",
    "    device = args.device,\n",
    ")\n",
    "\n",
    "test_iterator = Iterator(test_data, batch_size=args.batch_size,\n",
    "                        device=args.device, sort=False, sort_within_batch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameClassifier(nn.Module):\n",
    "    \"\"\" A 2-layer Multilayer Perceptron for classifying surnames \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim (int): the size of the input vectors\n",
    "            hidden_dim (int): the output size of the first Linear layer\n",
    "            output_dim (int): the output size of the second Linear layer\n",
    "        \"\"\"\n",
    "        super(SurnameClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            apply_softmax (bool): a flag for the softmax activation\n",
    "                should be false if used with the Cross Entropy losses\n",
    "        Returns:\n",
    "            the resulting tensor. tensor.shape should be (batch, output_dim)\n",
    "        \"\"\"\n",
    "        intermediate_vector = F.relu(self.fc1(x_in))\n",
    "        prediction_vector = self.fc2(intermediate_vector)\n",
    "\n",
    "        if apply_softmax:\n",
    "            prediction_vector = F.softmax(prediction_vector, dim=1)\n",
    "\n",
    "        return prediction_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': args.learning_rate,\n",
    "            'epoch_index': 0,\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'test_loss': -1,\n",
    "            'test_acc': -1,\n",
    "            'model_filename': args.model_state_file}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    \"\"\"Handle the training state updates.\n",
    "\n",
    "    Components:\n",
    "     - Early Stopping: Prevent overfitting.\n",
    "     - Model Checkpoint: Model is saved if the model is better\n",
    "\n",
    "    :param args: main arguments\n",
    "    :param model: model to train\n",
    "    :param train_state: a dictionary representing the training state values\n",
    "    :returns:\n",
    "        a new train_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Save one model at least\n",
    "    if train_state['epoch_index'] == 0:\n",
    "        torch.save(model.state_dict(), train_state['model_filename'])\n",
    "        train_state['stop_early'] = False\n",
    "\n",
    "    # Save model if performance improved\n",
    "    elif train_state['epoch_index'] >= 1:\n",
    "        loss_tm1, loss_t = train_state['val_loss'][-2:]\n",
    "\n",
    "        # If loss worsened\n",
    "        if loss_t >= train_state['early_stopping_best_val']:\n",
    "            # Update step\n",
    "            train_state['early_stopping_step'] += 1\n",
    "        # Loss decreased\n",
    "        else:\n",
    "            # Save the best model\n",
    "            if loss_t < train_state['early_stopping_best_val']:\n",
    "                torch.save(model.state_dict(), train_state['model_filename'])\n",
    "\n",
    "            # Reset early stopping step\n",
    "            train_state['early_stopping_step'] = 0\n",
    "\n",
    "        # Stop early ?\n",
    "        train_state['stop_early'] = \\\n",
    "            train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "\n",
    "    return train_state\n",
    "\n",
    "def compute_accuracy(y_pred, y_target):\n",
    "    _, y_pred_indices = y_pred.max(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_target).sum().item()\n",
    "    return n_correct/len(y_pred_indices) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SurnameClassifier(\n",
      "  (fc1): Linear(in_features=81, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=18, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740c306cac174b74886ef6e6008f2d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='training routine', style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f848d662b4145dc9da088b571a2a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=train', max=121.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a88b576e55458a99e1b23db8ebbb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='split=val', max=26.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = SurnameClassifier(input_dim=len(SURNAME.vocab.itos)-1, \n",
    "                               hidden_dim=args.hidden_dim, \n",
    "                               output_dim=len(NATIONALITY.vocab.itos))\n",
    "print(classifier)\n",
    "\n",
    "data_loaders = {\"train\": train_iterator, \"val\": val_iterator, \"test\": test_iterator}\n",
    "datasets = {\"train\": train_data, \"val\": val_data, \"test\": test_data}\n",
    "\n",
    "classifier = classifier.to(args.device)\n",
    "weights = 1/torch.tensor([NATIONALITY.vocab.freqs[c] for c in NATIONALITY.vocab.itos], dtype=torch.float)\n",
    "loss_func = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', factor=0.5,\n",
    "                                                 patience=1)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='training routine', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "train_bar = tqdm_notebook(desc='split=train',\n",
    "                          total=len(data_loaders[\"train\"]), \n",
    "                          position=1, \n",
    "                          leave=True)\n",
    "\n",
    "val_bar = tqdm_notebook(desc='split=val',\n",
    "                        total=len(data_loaders[\"val\"]), \n",
    "                        position=1, \n",
    "                        leave=True)\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(args.num_epochs):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "\n",
    "        # Iterate over training dataset\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        classifier.train()\n",
    "\n",
    "        for batch_index, batch_dict in enumerate(data_loaders[\"train\"]):\n",
    "            # the training routine is these 5 steps:\n",
    "\n",
    "            # --------------------------------------\n",
    "            # step 1. zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # step 2. compute the output\n",
    "            \n",
    "            x_in = oh_vectorizer.vectorize(batch_dict.surname)\n",
    "            y_pred = classifier(x_in=x_in.float())\n",
    "\n",
    "            # step 3. compute the loss\n",
    "            loss = loss_func(y_pred, batch_dict.nationality.long())\n",
    "            loss_t = loss.item()\n",
    "            running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "            # step 4. use loss to produce gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # step 5. use optimizer to take gradient step\n",
    "            optimizer.step()\n",
    "            # -----------------------------------------\n",
    "            # compute the accuracy\n",
    "            acc_t = compute_accuracy(y_pred, batch_dict.nationality)\n",
    "            running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "            # update bar\n",
    "            train_bar.set_postfix(loss=running_loss, \n",
    "                                  acc=running_acc, \n",
    "                                  epoch=epoch_index)\n",
    "            train_bar.update()\n",
    "\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_acc'].append(running_acc)\n",
    "\n",
    "        # Iterate over val dataset\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        classifier.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_index, batch_dict in enumerate(data_loaders[\"val\"]):\n",
    "\n",
    "                # compute the output\n",
    "                x_in = oh_vectorizer.vectorize(batch_dict.surname)\n",
    "                y_pred = classifier(x_in=x_in.float())\n",
    "\n",
    "                # step 3. compute the loss\n",
    "                loss = loss_func(y_pred, batch_dict.nationality.long())\n",
    "                loss_t = loss.item()\n",
    "                running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "                # compute the accuracy\n",
    "                acc_t = compute_accuracy(y_pred, batch_dict.nationality)\n",
    "                running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "                val_bar.set_postfix(loss=running_loss, \n",
    "                                    acc=running_acc, \n",
    "                                    epoch=epoch_index)\n",
    "                val_bar.update()\n",
    "\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_acc'].append(running_acc)\n",
    "\n",
    "        train_state = update_train_state(args=args, model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Exiting loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618341563da9453daad92aeebe1b7eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# compute the loss & accuracy on the test set using the best available model\n",
    "\n",
    "# classifier.load_state_dict(torch.load(train_state['model_filename']))\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "\n",
    "running_loss = 0.\n",
    "running_acc = 0.\n",
    "classifier.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch_dict in tqdm_notebook(enumerate(data_loaders[\"test\"]), \n",
    "                                                total = len(data_loaders[\"test\"])):\n",
    "        # compute the output\n",
    "        x_in = oh_vectorizer.vectorize(batch_dict.surname)\n",
    "        y_pred = classifier(x_in=x_in.float())\n",
    "\n",
    "        # compute the loss\n",
    "        loss = loss_func(y_pred, batch_dict.nationality.long())\n",
    "        loss_t = loss.item()\n",
    "        running_loss += (loss_t - running_loss) / (batch_index + 1)\n",
    "\n",
    "        # compute the accuracy\n",
    "        acc_t = compute_accuracy(y_pred, batch_dict.nationality)\n",
    "        running_acc += (acc_t - running_acc) / (batch_index + 1)\n",
    "\n",
    "train_state['test_loss'] = running_loss\n",
    "train_state['test_acc'] = running_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.716\n",
      "Test Accuracy: 47.16\n"
     ]
    }
   ],
   "source": [
    "print(\"Test loss: {:.3f}\".format(train_state['test_loss']))\n",
    "print(\"Test Accuracy: {:.2f}\".format(train_state['test_acc']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_nationality(surname, classifier, surname_field, nationality_field, oh_vectorizer):\n",
    "    \"\"\"Predict the nationality from a new surname\n",
    "    \n",
    "    Args:\n",
    "        surname (str): the surname to classifier\n",
    "        classifier (SurnameClassifer): an instance of the classifier\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        a dictionary with the most likely nationality and its probability\n",
    "    \"\"\"\n",
    "    surname = [char.lower() for char in surname]\n",
    "    surname = surname_field.numericalize([surname])\n",
    "    vectorized_surname = oh_vectorizer.vectorize(surname)\n",
    "    result = classifier(vectorized_surname.float(), apply_softmax=True)\n",
    "\n",
    "    probability_values, indices = result.max(dim=1)\n",
    "    index = indices.item()\n",
    "    \n",
    "\n",
    "    predicted_nationality = nationality_field.vocab.itos[index]\n",
    "    probability_value = probability_values.item()\n",
    "\n",
    "    return {'nationality': predicted_nationality, 'probability': probability_value}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McMahan -> scottish (p=0.37)\n"
     ]
    }
   ],
   "source": [
    "new_surname = \"McMahan\"\n",
    "classifier = classifier.to(\"cpu\")\n",
    "prediction = predict_nationality(new_surname, classifier, SURNAME, NATIONALITY, oh_vectorizer)\n",
    "print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                    prediction['nationality'],\n",
    "                                    prediction['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TopK Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_topk_nationalities(surname, classifier, surname_field, nationality_field, oh_vectorizer, k):\n",
    "    \"\"\"Predict the nationality from a new surname\n",
    "    \n",
    "    Args:\n",
    "        surname (str): the surname to classifier\n",
    "        classifier (SurnameClassifer): an instance of the classifier\n",
    "        vectorizer (SurnameVectorizer): the corresponding vectorizer\n",
    "    Returns:\n",
    "        a dictionary with the most likely nationality and its probability\n",
    "    \"\"\"\n",
    "    surname = [char.lower() for char in surname]\n",
    "    surname = surname_field.numericalize([surname])\n",
    "    vectorized_surname = oh_vectorizer.vectorize(surname)\n",
    "    result = classifier(vectorized_surname.float(), apply_softmax=True)\n",
    "    probability_values, indices = result.topk(dim=1, k=k)\n",
    "    probability_values = probability_values.view(-1)\n",
    "    index = indices.view(-1)\n",
    "    \n",
    "    results = []\n",
    "    for idx_, idx in enumerate(index):\n",
    "        predicted_nationality = nationality_field.vocab.itos[idx.item()]\n",
    "        probability_value = probability_values[idx_].item()\n",
    "        results.append({'nationality': predicted_nationality, 'probability': probability_value})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions:\n",
      "===================\n",
      "McMahan -> scottish (p=0.37)\n",
      "McMahan -> irish (p=0.17)\n",
      "McMahan -> german (p=0.11)\n",
      "McMahan -> czech (p=0.10)\n",
      "McMahan -> english (p=0.08)\n"
     ]
    }
   ],
   "source": [
    "new_surname = \"McMahan\"\n",
    "k = 5\n",
    "classifier = classifier.to(\"cpu\")\n",
    "predictions = predict_topk_nationalities(new_surname, classifier, SURNAME, NATIONALITY, oh_vectorizer, k)\n",
    "\n",
    "print(\"Top {} predictions:\".format(k))\n",
    "print(\"===================\")\n",
    "for prediction in predictions:\n",
    "    print(\"{} -> {} (p={:0.2f})\".format(new_surname,\n",
    "                                        prediction['nationality'],\n",
    "                                        prediction['probability']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
